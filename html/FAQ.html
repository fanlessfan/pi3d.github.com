<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Frequently Asked Questions &mdash; pi3d 1.10 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.10',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="pi3d 1.10 documentation" href="index.html" />
    <link rel="next" title="3D Graphics Explanation" href="GPUexplain.html" />
    <link rel="prev" title="Introduction to Pi3D" href="ReadMe.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="GPUexplain.html" title="3D Graphics Explanation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="ReadMe.html" title="Introduction to Pi3D"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">pi3d 1.10 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="frequently-asked-questions">
<h1>Frequently Asked Questions<a class="headerlink" href="#frequently-asked-questions" title="Permalink to this headline">¶</a></h1>
<ol class="arabic">
<li><p class="first">When starting any demo I get an AssertionError in DisplayOpenGL
<tt class="docutils literal"><span class="pre">assert</span> <span class="pre">s</span> <span class="pre">&gt;=</span> <span class="pre">0</span></tt></p>
<blockquote>
<div><p>This is generally caused by the graphics memory allocation on the
Raspberry Pi being too low (less than 32)</p>
</div></blockquote>
</li>
<li><p class="first">When starting any demo I get an AssertionError in DisplayOpenGL
<tt class="docutils literal"><span class="pre">assert</span> <span class="pre">self.surface</span> <span class="pre">!=</span> <span class="pre">EGL_NO_SURFACE</span></tt></p>
<blockquote>
<div><p>This is generally caused by the graphics memory allocation on the
Raspberry Pi being too low (less than 64)</p>
</div></blockquote>
</li>
<li><p class="first">When running ConferenceHall (or other program with a large number of
textures) it appears to start ok then shuts down (byebye 3 message) just
before the main display loop should appear.</p>
<blockquote>
<div><p>This is generally caused by the graphics memory allocation on the
Raspberry Pi being too low (less than 128)</p>
</div></blockquote>
</li>
<li><p class="first">When starting TigerTank, ConferenceHall or MarsStation demos I get an
error <tt class="docutils literal"><span class="pre">_tkinter.TclError:</span> <span class="pre">couldn't</span> <span class="pre">connect</span> <span class="pre">to</span> <span class="pre">display</span> <span class="pre">&quot;:0&quot;</span></tt></p>
<blockquote>
<div><p>tkinter is trying to use a display provided by the X-server. Run
startx from the command line.</p>
</div></blockquote>
</li>
<li><p class="first">I am trying to install using PiStore but it&#8217;s been running for hours
with no sign of completing.</p>
<blockquote>
<div><p>The PiStore install adds <cite>pip</cite> and <cite>Pillow</cite> which take quite a bit
of the cpu resources. It could be that you have set the graphics memory share
to the higher level needed to run pi3d. In the long run it will be quicker
to abort the installation, remove the half installed pi3d, use
raspi-config to set the graphics memory low, re-install pi3d, then
set the graphics memory back up again!</p>
</div></blockquote>
</li>
<li><p class="first">I have installed using PiStore and run the demos from the Menu. Now
I would like to play around for myself.</p>
<blockquote>
<div><p>There is a PiStore button next to <cite>launch</cite> that lets you see the source
code. It should open a file browser window to
<cite>/usr/local/indiecity/InstalledApps/skillmanmedia/Full/pi3d_demos</cite>
which is a very obscure location and also protected against modification.
To play around with the code you should either copy the whole
of this directory to your home directory (i.e. so you have
<cite>/home/pi/pi3d_demos/</cite>) or clone or download the demos from
<a class="reference external" href="http://github.com/pi3d/pi3d_demos">http://github.com/pi3d/pi3d_demos</a> (which will include a couple of
other demos excluded from PiStore because they use very large resource
files.)</p>
<p>Before going too far it would be a good idea to <a class="reference external" href="http://pi3d.github.com/html/index.html">ReadMe</a></p>
</div></blockquote>
</li>
<li><p class="first">When I try and run the demos I just get a load of error messages such as
<tt class="docutils literal"><span class="pre">libEGL</span> <span class="pre">warning:</span> <span class="pre">GLX/DRI2</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">supported/failed</span> <span class="pre">to</span> <span class="pre">authenticate</span> <span class="pre">etc</span></tt></p>
<blockquote>
<div><p>The chances are this is because &#8216;something&#8217; (such as gedit) has installed
mesa which added its own versions of libEGL and libGLESv2. If
you run:</p>
<div class="highlight-python"><div class="highlight"><pre>$ sudo find / -name libEGL*
$ sudo find / -name libGLESv2*
</pre></div>
</div>
<p>you should just get /opt/vc/lib/libEGL.so and /opt/vc/lib/libGLESv2.so
if other ones turn up i.e. /usr/lib/arm-linux-gnueabihf/libEGL.so.1
you could try creating symbolic links for them all like this:</p>
<div class="highlight-python"><div class="highlight"><pre>$ sudo ln -fs /opt/vc/lib/libEGL.so /usr/lib/arm-linux-gnueabihf/libEGL.so
$ sudo ln -fs /opt/vc/lib/libEGL.so /usr/lib/arm-linux-gnueabihf/libEGL.so.1
$ sudo ln -fs /opt/vc/lib/libGLESv2.so /usr/lib/arm-linux-gnueabihf/libGLESv2.so
$ sudo ln -fs /opt/vc/lib/libGLESv2.so /usr/lib/arm-linux-gnueabihf/libGLESv2.so.2
</pre></div>
</div>
<p>Using the actual paths as listed by find. Or just delete them as I did
<strong>NB DON&#8217;T DELETE THE ONES IN /opt/vc/lib</strong> After creating symbolic links
or deleting the new files you will need to run:</p>
<div class="highlight-python"><div class="highlight"><pre>$ sudo ldconfig
</pre></div>
</div>
<p>This issue is being looked into by the maintainers of Raspbian so,
hopefully, it will be fixed in later releases.</p>
</div></blockquote>
</li>
<li><p class="first">My RPi Crashes or reboots when I try and run a demo.</p>
<blockquote>
<div><p>Any program using a loadable texture, which includes nearly all the demos,
requires the Python Imaging module (PIL). Additionally, some demos require tk.</p>
<p>See the <a class="reference external" href="http://pi3d.github.com/html/index.html">ReadMe</a> for information on how to install these packages.</p>
</div></blockquote>
</li>
<li><p class="first">I see nothing but a white screen.</p>
<blockquote>
<div><p>Possibly something has gone wrong with an opengles function, sometimes
there might be an error message in the terminal such as failed to create
display. This could be caused by running out of gpu memory (see <a class="reference external" href="http://pi3d.github.com/html/index.html">ReadMe</a>
for how to set up memory split).</p>
<p>Occasionally multi-threaded applications can cause this problem if an
opengles function call is made not from the main thread.  If you encounter
this, please contact the pi3d team so we can protect against this in
future.</p>
</div></blockquote>
</li>
<li><p class="first">I see nothing but a black screen.</p>
<blockquote>
<div><p>Possibly something has gone wrong in a shader, such as using a shader
requiring texture coords (i.e. mat_relfect) on a Model exported with
no uv mapping.</p>
<p>There may be a line number reference output by the shader compiler in the
terminal window.  It is great fun experimenting with shaders but they are
<em>?£#%</em> taciturn beasts to debug! The problem could be caused by sending
some bad render setting to a shader.</p>
</div></blockquote>
</li>
<li><p class="first">I see nothing but the background.</p>
<blockquote>
<div><p>You will need to set background to non-transparent and a color not equal
to black or white to determine if this is happening.</p>
<p>Either the shape is behind the camera, too far away, is outside the field
of view, is too small, too large or the polygons are facing away from the
camera. Often this is because you are actually <strong>inside</strong> the object.</p>
<p>Try using the Camera.point_at([x,y,z]) function (see demos/ClashWalk.py
for use) or move and rotate the object and camera. Sprite and ImageSprite
shapes are one sided so cannot be seen from behind, try using a Plane
instead</p>
</div></blockquote>
</li>
<li><p class="first">I see only black silhouettes against the background.</p>
<blockquote>
<div><p>You may be trying to use a shader that requires light but there isn&#8217;t
any, or it&#8217;s turned down too low. Try switching to a &#8216;flat&#8217; shader
to check.</p>
<p>Alternatively, if it&#8217;s a shape you have generated such as
a Lathe or a Model, the normal vectors might be pointing in the wrong
direction. Try re-generating the shape, the path you use for the Lathe
needs to start at the top of the object and there are functions in
most 3D modeling applications to recalculate normals, or force them
to point outwards.</p>
</div></blockquote>
</li>
<li><p class="first">The demo loads but the mouse doesn&#8217;t move the camera as it&#8217;s supposed to.</p>
<blockquote>
<div><p>If this only happens on demos using the <tt class="docutils literal"><span class="pre">event</span></tt> library (such as Silo.py)
then it could be the hardware configuration is pretending to be something
it isn&#8217;t. It&#8217;s not uncommon for keyboards to say they are mice or
joysticks.</p>
<p>If you have a mouse combined with a keyboard (to save on USB slots) then
you might need to use <tt class="docutils literal"><span class="pre">get_mouse_movements(1)</span></tt>. If you have problems
with a device or inputs using the event system it&#8217;s a good idea to run
<tt class="docutils literal"><span class="pre">python</span> <span class="pre">FindDevices.py</span></tt> from <tt class="docutils literal"><span class="pre">pi3d/event/</span></tt> - this will give you lots
of additional information.</p>
<p>There is also an application <tt class="docutils literal"><span class="pre">demos/TestEvents.py</span></tt> that you can run to
find what information is being returned by your input devices. In some
circumstances you might need to modify the values returned by the
<tt class="docutils literal"><span class="pre">pi3d/event/Event.py</span> <span class="pre">InputEvents</span></tt> methods. TODO at the moment this
involves hacking the file but it will use a lookup table.</p>
<p>When running on my laptop (lenovo T420, ubuntu 13.10), occasionally, the
mouse doesn&#8217;t work with the <tt class="docutils literal"><span class="pre">event</span></tt> input, but starts to do after
running <tt class="docutils literal"><span class="pre">demos/TestEvents.py</span></tt> and changing the number in
<tt class="docutils literal"><span class="pre">get_mouse_movements()</span></tt> a few times. It&#8217;s not clear what causes this
but it might be when the USB mouse is plugged in after the computer
has been booted up.</p>
</div></blockquote>
</li>
<li><p class="first">It appears from the demos that there are some arguments that are optional.
For example, can a Shape be drawn without specifying a shader and a texture?</p>
<blockquote>
<div><p>There are (almost too) many ways to set Shapes up to draw. The draw method
needs to have a <strong>Shader</strong>, a <strong>Light</strong> and a <strong>Camera</strong> specified but if
you neglect to create a Light and Camera when you first draw a Shape it
will generate &#8216;default instances&#8217; which most of the time are just what you
want. (These default instances can be accessed to change settings such as
color or direction for a Light or field of view for a Camera by using the
syntax: <tt class="docutils literal"><span class="pre">Camera.instance()</span></tt>.</p>
<p>You do, however need to explicitly
create the Shader so it does the kind of rendering you want, but you
can feed that in by various means, many of which also cater for specifying
the Texture(s) to use as well:</p>
<blockquote>
<div><p>Set them directly in the Buffer array - the other methods are
really just wrappers for this i.e.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">myshape</span><span class="o">.</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shader</span> <span class="o">=</span> <span class="n">myshader</span>
<span class="n">myshape</span><span class="o">.</span><span class="n">buf</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">textures</span> <span class="o">=</span> <span class="p">[</span><span class="n">mytexture</span><span class="p">]</span>
</pre></div>
</div>
<p>Include them
at draw time:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">myshape</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">myshader</span><span class="p">,</span> <span class="p">[</span><span class="n">mytexture</span><span class="p">])</span>
</pre></div>
</div>
<p>Set them beforehand
(probably the most usual way):</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">myshape</span><span class="o">.</span><span class="n">set_draw_details</span><span class="p">(</span><span class="n">myshader</span><span class="p">,</span> <span class="p">[</span><span class="n">mytexture</span><span class="p">])</span>
</pre></div>
</div>
<p>For Model objects the ambient texture or material shade will normally
be defined in the 3D object file (egg or obj/mtl) In these cases
you could use:</p>
<div class="highlight-python"><div class="highlight"><pre>myshape.set_shader(myshader)
...
myshape.set_normal_shine(normtex, ntiles..) # leaves the first texture if there
...
myshape.set_material(mtrl)
</pre></div>
</div>
</div></blockquote>
</div></blockquote>
</li>
<li><p class="first">How can I blend objects, why do objects vanish when they go behind a transparent
object and other questions to do with transparency (or apha property)</p>
<blockquote>
<div><p>Transparency of Shapes can be altered by 1. the set_alpha() method 2. the
alpha value of pixels in a png type image file 3. alpha value of the fog.
The blending of the pixels with alpha less than 1.0 is controlled by setting
Texture.blend to True or False.</p>
<p>The way that transparency is handled is quite hard to understand. Here is
some good information <a class="reference external" href="http://www.opengl.org/wiki/Transparency_Sorting">http://www.opengl.org/wiki/Transparency_Sorting</a></p>
<p>The graphics processor has a global setting to enable blending that is
switched on or off as each Shape is drawn, allowing or preventing the pixels
to be blended with whatever&#8217;s behind them. In pi3d this can be controlled by
setting the <tt class="docutils literal"><span class="pre">blend=True</span></tt> argument when the Texture is created or at a later
point by <tt class="docutils literal"><span class="pre">mytexture.blend</span> <span class="pre">=</span> <span class="pre">True</span></tt> In addition to this setting there is a check
in the draw() method so that blend is enabled when alpha is set to less than 1.0.</p>
<p>When the gpu is rendering an object there is a depth buffer that holds
information on how far from the camera each pixel has been drawn. Because
of this it is normally optimal to draw foreground objects first as there
is then less of the background to fill in. If the background was drawn
first then the same pixel might have to be redrawn several times as the
gpu found something else nearer to the view point. However the gpu
<strong>doesn&#8217;t</strong> take into account the transparency of the pixel when it&#8217;s
deciding if something is nearer or further away, so for blending
you have to draw things on top of other things...</p>
<p>Which sounds obvious but to give an example; if a slideshow tries to blend
between two images, one drawn in front of the other:</p>
<p>If you <strong>first</strong> draw the canvasFront (z=0.1) with alpha=0.1
<strong>then</strong> draw the canvasBack (z=0.2) with alpha=0.9 the result will
be a very faint image on canvasFront and nothing on canvasBack. Wrong!</p>
<p>i.e. canvasBack always has to be drawn first and if the application is purely
fading from one image to another it can leave canvasBack at apha=1.0 (i.e.
default value) and just increase then decrease the alpha of canvasFront</p>
<p>In addition to blending, when the Shader is rendering an object it discards
some pixels without drawing anything at all. The decision is based on the
alpha value of the pixel as read from the Texture. If blend is True then
pixels with alpha &lt; 0.05 are discarded if blend is False then pixels with
alpha &lt; 0.6 are discarded. This allows objects to be drawn after nearer objects
but still be seen through &#8216;holes&#8217; in the image. i.e. the trees in ForestWalk</p>
</div></blockquote>
</li>
<li><p class="first">How do I use a joystick, gamepad, xbox controller etc with a pi3d
application?</p>
<blockquote>
<div><p>Often these will just work with the event module when plugged into the USB,
sometimes you may need to use a different InputEvents method, for instance
with an xbox 360 you get the left joystick from <tt class="docutils literal"><span class="pre">get_joystickB3d()</span></tt>
Also you would need to install the driver and start it running first:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo apt-get install xboxdrv
sudo xboxdrv -s -i 0
</pre></div>
</div>
</div></blockquote>
</li>
<li><p class="first">How do I make my own 3D model to load into pi3d?</p>
<blockquote>
<div><p>You will need to &#8216;make&#8217; one on a bigger computer using 3D software such
as <tt class="docutils literal"><span class="pre">blender</span></tt>. This falls outside the scope of this FAQ but your best
option is to export the model as an obj file. In Bl2.6 options I specify:</p>
<div class="highlight-python"><div class="highlight"><pre>Apply Modifiers (default)
Include Edges (default)
Include Normals (tick this) &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; *
Include UVs (default but see below)
Write Materials (default)
Object as OBJ Objects (default)

Forward -Z Forward (default)
Up Y Up (default)
these last two will mean that..
Blender.x=&gt;pi3d.x, Blender.y=&gt;pi3d.z, Blender.z=&gt;pi3d.y with no reflection
of whatever you design
</pre></div>
</div>
<p><tt class="docutils literal"><span class="pre">*</span></tt> If you export without getting blender to Include Normals then pi3d
will have to generate them when the model is loaded. This is not a
good idea for several reasons: It will be slower to do on the pi then
on a &#8216;big&#8217; computer, it will have to be done every time the model is
loaded rather than just once, it will not give the fine control
available in blender to define the sharpness of edges.</p>
<p>NB You will need to define uv mapping even if you define a material
colour and don&#8217;t intend to use a texture but might want to use a normal
mapping shader. To do this in blender you need to tab to edit mode, select
all vertices (a), unwrap (u, Unwrap). If the model has multiple objects
you will need to do this for each one. After you export you may need to
edit the <tt class="docutils literal"><span class="pre">mtl</span></tt> file so the relative path to the image is correct for
their locations on the pi. In programs such as blender it is also possible to
use a more detailed (high polygon) model to create a &#8216;normal map&#8217; image
that can be used to give surface detail to the model in pi3d. Quite
technical but lots of instructional videos on youtube!</p>
</div></blockquote>
</li>
<li><p class="first">Can I use pi3d for 2D images?</p>
<blockquote>
<div><p>There are various ways of doing this. The easiest way is to use the
image to texture a simple rectangle. The simplest shape to do this
is the Sprite which is also utilised by the ImageSprite shape to
allow the texture to be specified as it is created. The Plane object
is similar but is two sided. The advantage and disadvantage of this
method is that images will be different when viewed from different
locations.</p>
<p>If you specify an orthogrphic camera (set the argument
is_3d=False) then there will be no perspective (the image will not
get smaller as it moves away from the camera) and each unit of the
dimensions of the object will be one pixel on the screen. With both
these methods the shape can be rotated, moved and scaled in all
dimensions.</p>
<p>You can also use the shader 2d_flat which takes pixels from an image
and maps them to the screen, see below. The advantage of this
method is that it can use the even simpler Canvas object and it always
stays in the same place relative to the camera so you only need one
camera, which can be the default one that you don&#8217;t have to bother
creating. See below.</p>
</div></blockquote>
</li>
<li><p class="first">How do I display 2D images in front of a 3D scene? (or behind, for that
matter)</p>
<blockquote>
<div><p>Either draw them onto a Canvas object using the 2d_flat shader or
create two cameras one 3D and one 2D and assign the relevant camera
to the types of objects you want to be drawn by each method. You
can move the 3D camera around the scene but leave the 2D one stationary,
that way you won&#8217;t have to keep moving and rotating the 2D objects
to keep them in front of the camera.</p>
<p>Orthographic (2D) cameras will render objects with a z value that is
severely non linear and does not relate in a simple way to the z values
for the perspective camera. Generally 2D objects will be in front
of objects rendered by perspective (3D) cameras unless you assign
z values in the thousands. Too large a z value, though, and they will
disappear beyond the &#8216;far plane&#8217;</p>
<p>If you create a camera it will become the default instance so if you
need more than one you need to explicitly create them and it&#8217;s a good
idea to explicitly assign the one you want to each object.</p>
</div></blockquote>
</li>
<li><p class="first">How do I display an image exactly without anti-aliasing or smoothing
i.e. pixel perfect?</p>
<blockquote>
<div><p>This can be done by using the 2d_flat shader and spcifying when the
Texture is loaded that mipmap=False. Because this is a global setting
it will be overwritten by whichever Texture is the last to be loaded</p>
</div></blockquote>
</li>
<li><p class="first">Some of my Textures look a bit blurred or pixely.</p>
<blockquote>
<div><p>Early GPUs had to have image sizes of powers of 2 pixels. i.e.
2,4,8..1024,2048 because of the algorithm used for texture sampling,
but modern ones can manage with any dimensions. With the raspberry
pi we have found that some widths can cause rows of pixels to be
offset unless they fall on certain sizes (below). <strong>If the image
width is a value not in this list then it will be rescaled with a
resulting loss of clarity</strong></p>
<p>Allowed widths 4, 8, 16, 32, 48, 64, 72, 96, 128, 144, 192, 256, 288,
384, 512, 576, 640, 720, 768, 800, 960, 1024, 1080, 1920</p>
</div></blockquote>
</li>
<li><p class="first">When the demos start there is sometimes a message in the terminal
looking like:
<tt class="docutils literal"><span class="pre">2013-08-19</span> <span class="pre">15:36:46,232</span> <span class="pre">INFO:</span> <span class="pre">__main__:</span> <span class="pre">Starting</span> <span class="pre">CollisionBalls</span></tt>
Where does that come from and what does it mean?</p>
<blockquote>
<div><p>The Log module is started by several of the basic classes (Buffer,
EventStream, Display, Loadable, Mouse, parse_mtl, Shader, Screenshot)
This means that all programs using the pi3d modules will create a Log
as a by-product. It can be used for debugging and recording errors.</p>
</div></blockquote>
</li>
<li><p class="first">How do I use <tt class="docutils literal"><span class="pre">pi3d.Log</span></tt> to gather or display useful information
in my application?</p>
<blockquote>
<div><p>See the documentation
<a class="reference external" href="http://pi3d.github.io/html/pi3d.util.html#module-pi3d.util.Log/">here</a>.</p>
</div></blockquote>
</li>
<li><p class="first">How do I keep two components (Shapes) &#8216;joined together&#8217; as they pitch, roll
and rotate (yaw), like the TigerTank does with its body, turret and gun?</p>
<blockquote>
<div><p>First of all it is easiest if you make the zero points of all the shapes
coincide. When you move and rotate the objects you must move and rotate
them all by the same amount. If one component is rotated about the y axis
by a different amount from the others (i.e. the turret and gun) then
the difference is just added to the y rotation for that component.
However if the component is rotated about the y axis and the x axis
(i.e. the gun) then you have to adjust the x axis and the z axis rotation
by an amount that depends on the degree of y axis rotation. See the
drawTiger function in demos/TigerTank.py for the kind of formula to use.</p>
</div></blockquote>
</li>
<li><p class="first">I want to give my shape an angle of bank (z-axis rotation) which it
maintains as it turns (y-axis rotation) - like an aeroplane. However the
z-rotation is always relative to the absolute frame of reference so the shape
pitches backwards and forwards as it turns. How do I make the frame of
reference rotate with the shape?</p>
<blockquote>
<div><p>This is because of the order of the transformations done prior to
redrawing the scene (z, then x, then y). You have to work out what the pitch
and roll would have to be prior to rotating them about their own y axis!
To see what I mean watch the behaviour of the tanks in demos/TigerTank.py
You have to figure out the &#8216;slope of the ground&#8217; so that when your
aeroplane (or boat) is rotated it ends up with the correct pitch and
roll. For a shape with zero pitch you can use something like:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">absheel</span> <span class="o">=</span> <span class="n">degrees</span><span class="p">(</span><span class="n">asin</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">radians</span><span class="p">(</span><span class="n">heel</span><span class="p">))</span> <span class="o">*</span> <span class="n">cos</span><span class="p">(</span><span class="n">radians</span><span class="p">(</span><span class="n">heading</span><span class="p">))))</span>
<span class="n">abspitch</span> <span class="o">=</span> <span class="n">degrees</span><span class="p">(</span><span class="n">asin</span><span class="p">(</span><span class="o">-</span><span class="n">sin</span><span class="p">(</span><span class="n">radians</span><span class="p">(</span><span class="n">heel</span><span class="p">))</span> <span class="o">*</span> <span class="n">sin</span><span class="p">(</span><span class="n">radians</span><span class="p">(</span><span class="n">heading</span><span class="p">))))</span>
<span class="n">hull</span><span class="o">.</span><span class="n">position</span><span class="p">(</span><span class="n">xm</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">zm</span><span class="p">)</span>
<span class="n">hull</span><span class="o">.</span><span class="n">rotateToX</span><span class="p">(</span><span class="n">abspitch</span><span class="p">)</span>
<span class="n">hull</span><span class="o">.</span><span class="n">rotateToY</span><span class="p">(</span><span class="o">-</span><span class="n">heading</span><span class="p">)</span>
<span class="n">hull</span><span class="o">.</span><span class="n">rotateToZ</span><span class="p">(</span><span class="n">absheel</span><span class="p">)</span>
</pre></div>
</div>
<p>And see the demos/DogFight.py version which has an extra degree
of freedom.</p>
</div></blockquote>
</li>
<li><p class="first">Is it possible to change the shape of an object once it&#8217;s been made?</p>
<blockquote>
<div><p>The most efficient way is to use the scale(sx, sy, sz) method. However,
this obviously limits the shape changing that can take place. If the
shape needs to be changed more than this then it can be remade as
a new instance to replace the old one. (At one stage it was necessary to
clear the previous opengles buffers using the unload_opengl() method
before destroying the old shape to stop a graphics memory leak.
This issue seems to be fixed but if you run into memory problems
it might be worth trying this. Plus, obviously, report it to us!)</p>
<p>The alternative way of doing it is to use the Buffer.re_init() method
which takes the same arguments as Buffer.__init__() (see documentation)
so is a little more technical to use.</p>
</div></blockquote>
</li>
<li><p class="first">Sometime, when I move the mouse or the program is loading a file from
disk, everything slows down or freezes.</p>
<blockquote>
<div><p>The Display has a frames_per_second argument and if you set this
lower than the flat out rate it will give the processor some &#8216;slack&#8217;
to accomplish other jobs.</p>
<p>To do things like file loading in the background (for instance, preloading
an image or Shape so that it can instantly appear later) you need to use
Python&#8217;s threading - demos/Slideshow_2d.py is an example.</p>
</div></blockquote>
</li>
<li><p class="first">I am running pi3d on a non-raspberry pi Linux machine but it&#8217;s running
at a very slow frame rate.</p>
<blockquote>
<div><p>Probably the GPU can&#8217;t run the OpenGL2+ code that mesa interprets
from the pi3d OpenGLES2 commands. Check the specification for the
graphics card. <tt class="docutils literal"><span class="pre">lspci</span> <span class="pre">-v</span></tt> and <tt class="docutils literal"><span class="pre">feedback.wildfiregames.com/report/opengl/</span></tt></p>
</div></blockquote>
</li>
<li><p class="first">Some of the demos on a non-raspberry pi Linux machine work fine but
other don&#8217;t run and give an error:</p>
<div class="highlight-python"><div class="highlight"><pre>IOError: [Errno 13] Permission denied: u&#39;/dev/input/mice&#39;
</pre></div>
</div>
<p>what is the
cause of this</p>
<blockquote>
<div><p>The Mouse gets its info from the operating system file described in
the error message. This requires it to be run from root, you can
do this by <tt class="docutils literal"><span class="pre">sudo</span> <span class="pre">python</span> <span class="pre">ForestWalk.py</span></tt>.</p>
</div></blockquote>
</li>
<li><p class="first">Using python3 and the InputEvents mouse input (Silo and DogFight demos)
I get very ragged and unresponsive camera movment.</p>
<blockquote>
<div><p>This should be fixed as of v1.5, try upgrading to the latest
version of pi3d</p>
</div></blockquote>
</li>
<li><p class="first">How do I do post-rendering processing on a scene, such as blurring,
edge detection or fancier effects such as oil painting.</p>
<blockquote>
<div><p>There is a class PostProcess that can be used to render a scene to
a texture. The Post.py demo shows a simple 3x3 convolution matrix
shader and there are a host of post process filter shaders that
are in the pi3d_demos/shaders directory. These wll be loaded in
turn by FilterDemo.py but the pi will run out of graphics memory
if you leave the full list in. For more complicated effects it&#8217;s
over to you!</p>
</div></blockquote>
</li>
<li><p class="first">OK the example for post processing (Post.py) is quite hard to follow
how exactly does the PostProcess class work.</p>
<blockquote>
<div><p>PostProcess inherits from Texture (via OffScreenTexture) so you can
use an instance of it anywhere you would use a texture, i.e. you
could uv map it onto any other shape or use it as a bump or
reflection map. Or use it with your own shader to do something I
haven&#8217;t thought of. PostProcess.sprite is a Sprite shape that can
be used just as any other Shape in your program, you could rotate
it or change its alpha value or z location to draw it in front of
other objects. There is also a 2D camera created in PostProcess
which is used to draw the sprite at full screen using the saved
texture and the shader you supply in the constructor or post_base
if you don&#8217;t supply one.</p>
<p>PostProcess.draw({48:1.1414, 49:2013, 50:0.0}) will set the unif
array in PostProcess.sprite as unif[48] = 1.1414 unif[49] = 2013
unif[50] = 0.0 you can then access these values as uniform
variables in your shader as vec3 unif[16][0] unfi[16][1]
unfi[16][2]. If the array indices are contiguous you could do the
same thing using PostProcess.sprite.set_custom_data(48, [1.1414,
2013, 0.0]) or even PostProcess.sprite.unif[48] = 1.1414 etc</p>
<p>I see no reason why you shouldn&#8217;t do something like:
render the scene to a texture once a second draw it off-screen using
a shader to extract edges as dayglo on white, blur them to a second
texture, draw this onto a foreground sprite fading from alpha 0 to
1 back to 0 over 1s cycle. Use a different shader to draw the original
texture onto a spherical surface that gradually changes shape in
the background. etc etc.</p>
</div></blockquote>
</li>
<li><p class="first">And why does python set Shape.unif[48] but the shader use
vec3 unif[16][0].</p>
<blockquote>
<div><p>On the shader side it&#8217;s really efficient to define variables as
vec3, vec4, mat4 etc. and at one stage I tried doing a lot of the
matrix manipulation in the vertex shader. There were pros and
cons but in the end I found that using python&#8217;s numpy library
was the best bet. But in the mean time I had started storing
much of the shape information in a form that allowed it to be
accessible by the shader i.e. location x,y,z was vec3 unif[0]
in the shader, rotation was vec3 unif[1], scale unif[2], origin
offset unif[3] etc. Although I no longer needed these for normal
rendering I thought that they may come in useful for someone at
some stage so I just left them. I only needed to pass one array
pionter so there was no cost to having 60 floats available!</p>
<p>Meanwhile back in the python description of the Shape I had to
make the unif array a ctypes.c_float array and that seemed to
have to be one-dimensional. So after a long story unif[16][0]
in the shader is (same name but different) unif[16*3 + 0] in python</p>
</div></blockquote>
</li>
<li><p class="first">How can you render points like a star field
or sparks from an explosion.</p>
<blockquote>
<div><p>If you use the method set_point_size() on a Shape to a value other
than 0.0 then the vertices of the Shape will be rendered as points.
The size will actually vary with distance but will be the size you
specified at 1 unit of distance from the camera.</p>
<p>pi3d.Points can be used to render points using the mat_flat shader</p>
</div></blockquote>
</li>
<li><p class="first">How can I set up an SD card without all of Raspbian&#8217;s clutter that will
boot quickly and allow me to run a dedicated pi3d application.</p>
<blockquote>
<div><p>I decided that Arch would be tidiest for this as it will comfortably
fit onto 2GB SD and boots in a few seconds. These were the steps:</p>
<p>1.  download and unzip the image from
<a class="reference external" href="http://www.raspberrypi.org/downloads">http://www.raspberrypi.org/downloads</a></p>
<p>2. follow the instructions from <a class="reference external" href="http://elinux.org/RPi_Easy_SD_Card_Setup">http://elinux.org/RPi_Easy_SD_Card_Setup</a>
to get the image onto the SD card</p>
<p>3. put card in Pi and boot it up.
log in as <tt class="docutils literal"><span class="pre">root</span></tt>, password <tt class="docutils literal"><span class="pre">root</span></tt> I didn&#8217;t change these or set
up a normal user account with sudo etc. as the card will just be
used for running one application not connected to the net. You may
want to do otherwise in which case look at this
<a class="reference external" href="http://elinux.org/ArchLinux_Install_Guide">http://elinux.org/ArchLinux_Install_Guide</a></p>
<p>4.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman-key</span> <span class="pre">--init</span></tt></p>
<p>4a.
&lt;Alt&gt;&lt;F2&gt; <tt class="docutils literal"><span class="pre">#</span> <span class="pre">ls</span> <span class="pre">-R</span> <span class="pre">/</span> <span class="pre">&amp;&amp;</span> <span class="pre">ls</span> <span class="pre">-R</span> <span class="pre">/</span> <span class="pre">&amp;&amp;</span> <span class="pre">ls</span> <span class="pre">-R</span> <span class="pre">/</span></tt></p>
<p>4b. &lt;Alt&gt;&lt;F1&gt; to get back to normal terminal, this is all to do with
generating entropy to get a random key (apparently).</p>
<p>5.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-Syu</span></tt> [update packages]</p>
<p>6.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">python2</span></tt></p>
<p>7.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">python2-numpy</span></tt></p>
<p>8.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">python2-pillow</span></tt></p>
<p>9.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">python2-pip</span></tt></p>
<p>10.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">git</span></tt></p>
<p>11. <tt class="docutils literal"><span class="pre">#</span> <span class="pre">pip2</span> <span class="pre">install</span> <span class="pre">pi3d</span> <span class="pre">--pre</span></tt> [the &#8211;pre flag tells it to install
even if pre-release version i.e. 1.7a]</p>
<p>12.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">cd</span> <span class="pre">/home/</span></tt></p>
<p>13. <tt class="docutils literal"><span class="pre">#</span> <span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/paddywwoof/sailsim.git</span></tt> [this would
be your actual repository, alternatively you could just copy the files
onto the SD card from a local machine]</p>
<p>if you need to access the RPi.GPIO
system from your application then you also need to</p>
<p>14.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pacman</span> <span class="pre">-S</span> <span class="pre">gcc</span></tt></p>
<p>15.
<tt class="docutils literal"><span class="pre">#</span> <span class="pre">pip2</span> <span class="pre">install</span> <span class="pre">RPi.GPIO</span></tt></p>
<p>if you want to make it a bit easier to start up the application
then you could make a little script file like this:</p>
<div class="highlight-python"><div class="highlight"><pre>#!/bin/bash
cd /home/sailsim/
python2 sailsim.py
</pre></div>
</div>
<p>called <tt class="docutils literal"><span class="pre">sailsim</span></tt> and you then put that file in the /usr/bin/ directory
and make it executable <tt class="docutils literal"><span class="pre">#</span> <span class="pre">chmod</span> <span class="pre">+x</span> <span class="pre">sailsim</span></tt> then after logging in
you will just be able to type <tt class="docutils literal"><span class="pre">#</span> <span class="pre">sailsim</span></tt> and start the app.</p>
<p>I did managage to get the app to start &#8216;automatically&#8217; <em>before</em> logging
in by adding the file below as /etc/systemd/system/start_sailsim.service</p>
<div class="highlight-python"><div class="highlight"><pre>[Unit]
Description=Run sailsim on boot
After=network.target
[Service]
Type=oneshot
ExecStart=/usr/bin/sailsim
[Install]
WantedBy=multi-user.target
</pre></div>
</div>
<p>Then run <tt class="docutils literal"><span class="pre">#</span> <span class="pre">systemctl</span> <span class="pre">enable</span> <span class="pre">start_sailsim.service</span></tt> However there
were unsatisfactory side effects to do with timing which meant I
could not use it in this way.</p>
</div></blockquote>
</li>
<li><p class="first">Does pi3d work
with pypy</p>
<blockquote>
<div><p>pi3d relies on some of the functionality and speed of numpy and this
only really became useable as of pypy-2.2 and I have managed to get
pi3d working to some extent with that. At the moment that isn&#8217;t the
current version you get with apt-get so these were the steps I took:</p>
<p>1. download the relevant version from <a class="reference external" href="http://pypy.org/download.html">http://pypy.org/download.html</a>
for your machine (Ubuntu, raspbian etc) extract it into a new directory
i.e. /home/me/pypy-2.2.1-linux64</p>
<p>2. in a
terminal:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo apt-get install pypy-dev
</pre></div>
</div>
<p>3. download and install pypy-numpy so it&#8217;s also in a subdirectory
of pypy-x.x.x-etc I did this cd to that directory then using:</p>
<div class="highlight-python"><div class="highlight"><pre>git clone https://bitbucket.org/pypy/numpy.git
cd numpy
sudo ../bin/pypy setup.py install
</pre></div>
</div>
<p>4.* download Pillow from <a class="reference external" href="https://pypi.python.org/pypi/Pillow">https://pypi.python.org/pypi/Pillow</a> and
extract it into its own subdirectory of pypy-x.x.x-etc i.e.
/home/me/pypy-2.2.1-linux64/Pillow-2.2.1</p>
<p>5.* download <a class="reference external" href="http://python-distribute.org/distribute_setup.py">http://python-distribute.org/distribute_setup.py</a> to
pypy-x.x.x-etc/bin and run it:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo ./pypy distribute_setup.py
</pre></div>
</div>
<p>6.* either cd to pypy-x.x.x-etc/bin
and run:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo ./easy_install Pillow
</pre></div>
</div>
<p>7.* or cd to the Pillow-x.x directory
and run:</p>
<div class="highlight-python"><div class="highlight"><pre>sudo ../bin/pypy setup.py install
</pre></div>
</div>
<p>I did different permutations of these things but confused myself as
to which I was &#8216;really&#8217; doing (by occasionally forgetting to type
<tt class="docutils literal"><span class="pre">./pypy</span></tt> and thereby running a debian package version that was
also installed) so some of these steps are redundant. Also other
steps may be missing.</p>
<p>At the moment (Dec13
<a class="reference external" href="https://github.com/tipam/pi3d/commit/ce5febc6693115872c7e4653dfea503e029fa0d5">https://github.com/tipam/pi3d/commit/ce5febc6693115872c7e4653dfea503e029fa0d5</a>)
the changes to Shape.draw() have been commented out because they
look to add some extra processing at an expensive location. If
you want to try pypy you will have to swap the two lines (search
for pypy to find them)</p>
</div></blockquote>
</li>
<li><p class="first">How can I make my own EnvironmentCube images using pictures of my
garden or school playground?</p>
<blockquote>
<div><p>Option 1. Using an EnvironmentCube (as the question says) but see
below for using a Sphere, which is probably easier.</p>
<p>There are lots of ways of doing this and different software as well
as special cameras. However this is the method I have followed using
freely available software: gimp and blender (running on a &#8216;normal&#8217;
computer rather than the pi at this stage).</p>
<p>The first half of the job is to get a set of images into a &#8216;seamless&#8217;
band. Obviously you need to have taken a set of pictures that overlap
25% to 50%. In gimp make a new image that is higher and wider than
you will need to paste all the images side by side. You will need to
have the same image repeated at the left end and the right end.</p>
<p>Open each image in gimp then copy it, go to the new &#8216;wide strip&#8217;
image and paste as new layer. Use the four headed arrow to position
each layer so it &#8216;joins up&#8217;. When you put the duplicate left most
image at the right end you need to make sure that it is at exactly
the same vertical position as it is on the left.</p>
<p>Working down from the top layer add layer masks (default white, full
opacity) then using gradient fill tool make the mask fade from
transparent to opaque across the overlapping portion. You might need
to slightly rotate some images to make them join up nicely from one
side to the other.</p>
<p>When it looks perfect (!) merge the layers down then crop the image
so there are no gaps at the top and bottom and so the left and right
edges join seamlessly. You will probably have to zoom to maximum and
choose an easily identifiable pixel. The rectangular selection tool
in gimp allows the edges to be dragged to fine tune it. Export the
image to jpg or png possibly after reducing to a reasonable size. Have
some suitable sky only image to patch into the top of the sphere you
will create in blender...</p>
<p>I used blender 2.69, it&#8217;s not a trivial application if you&#8217;ve not used
it before and it might take a bit of effort to figure out what I&#8217;m
referring to [tab] means tab key, otherwise it&#8217;s probably a menu
item or an icon in the right hand. Lots of youtube videos to look at.
In blender:</p>
<p>1. [del] delete the
startup cube</p>
<p>2. <tt class="docutils literal"><span class="pre">Add</span> <span class="pre">Mesh</span> <span class="pre">UV</span> <span class="pre">Sphere</span></tt>, on left tools
set <tt class="docutils literal"><span class="pre">Shading</span> <span class="pre">Smooth</span></tt></p>
<p>3. [s] to scale up
to about 10x</p>
<p>4. [tab] to edit mode [a] to deselect all vertices. R-click on top
vertex the Ctrl-numpad+ to select vertices down to about 45 degrees
north (or use [b] and box select) [del] delete vertices. You should
now have a sphere with the top cut off</p>
<p>5. [tab] back to object mode then create another sphere at the same
location but scale it up very slightly bigger and chop off the bottom
but so they overlap just a little.</p>
<p>6. [tab] back to object mode then <tt class="docutils literal"><span class="pre">Add</span> <span class="pre">Empty</span> <span class="pre">Cube</span></tt> at the same location
(NB if you accidentally left click on the view window you will move
the starting point marker where new things appear). You should be able
to zoom in with the mouse wheel and see this cube inside the spheres.</p>
<p>7. still in object mode right click to select the bottom (inner and larger)
sphere. The edge should go yellow to indicate it&#8217;s been selected.</p>
<p>8. on the right properties window click the Materials icon (CofG circle
4th from right), then + new.</p>
<p>9. then click the Textures icon (red/white check 3rd from right),
then + new, <tt class="docutils literal"><span class="pre">Type</span> <span class="pre">Image</span> <span class="pre">or</span> <span class="pre">movie</span></tt>, <tt class="docutils literal"><span class="pre">Image</span> <span class="pre">New</span></tt> browse to the wide horizon
image you made, <tt class="docutils literal"><span class="pre">Mapping</span> <span class="pre">Projection</span> <span class="pre">Tube</span></tt></p>
<p>10. still in object mode right click on the top sphere, add material and
texture exactly as for the bottom sphere but select the patch of sky
image mentioned above and choose <tt class="docutils literal"><span class="pre">Mapping</span> <span class="pre">Projection</span> <span class="pre">Flat</span></tt></p>
<p>11. in object mode right click on the Empty Cube and add a new Texture (you
should see a reduced list of options so it&#8217;s 2nd from right in the list)</p>
<p>12. select under <tt class="docutils literal"><span class="pre">Type</span> <span class="pre">Environment</span> <span class="pre">Map</span></tt> then under <tt class="docutils literal"><span class="pre">Environment</span> <span class="pre">Map</span> <span class="pre">Static</span></tt>,
<tt class="docutils literal"><span class="pre">Mapping</span> <span class="pre">Cube</span></tt> and <tt class="docutils literal"><span class="pre">Viewpoint</span> <span class="pre">Object</span>&nbsp; <span class="pre">Empty</span></tt></p>
<p>13. in the properties icons select render (camera left most) then under
Render press the render button. This should flash up a series of six
smaller images then go black!</p>
<p>14. re-select the Texture icon (all of these steps should have the Empty
Cube as the selected object) and the little down arrow under Environment
Map should produce a drop-down menu with an option to save the image.</p>
<p>The texture can then be used in pi3d with EnvironmentMap type BLENDER. However
there will be a sharp line where the edge of the bottom sphere fell. You can
smooth this out using clone, repair, blur and blend tools in gimp; be
careful not to blur the boundaries between the six images.</p>
</div></blockquote>
</li>
<li><p class="first">How do I make an Environment Sphere (such as can use the Photo Sphere
images created by later versions of Android)</p>
<blockquote>
<div><p>First you need an image very much like the one outlined in the previous
question. If you have the software on your phone or tablet to do a
Photo Sphere that&#8217;s going to be a lot easier but you can do something
similar with a series of panoramas as modern cameras can make. The
image needs to be twice as wide as it is high using a standard cylindrical
projection <a class="reference external" href="http://en.wikipedia.org/wiki/Equirectangular_projection">http://en.wikipedia.org/wiki/Equirectangular_projection</a></p>
<p>This image is used for a Texture uv mapped to a standard pi3d.Sphere
but the Texture needs to have the argument <tt class="docutils literal"><span class="pre">flip=True</span></tt> and the Sphere
needs the argument <tt class="docutils literal"><span class="pre">invert=True</span></tt></p>
</div></blockquote>
</li>
<li><p class="first">How can I speed up loading Models. Even quite low polygon counts
seem to take ages on the Raspberry Pi</p>
<blockquote>
<div><p>Thanks to Avishay <a class="reference external" href="https://github.com/avishorp">https://github.com/avishorp</a> it is possible to use
the python pickle functionality to serialise pi3d Shapes including
Model. [develop branch as at 2014-05-07]</p>
<p>There is an example on github.com/pi3d/pi3d_demos
LoadModelPickle.py which shows the process but basically:</p>
<blockquote>
<div><p>load the models once normally, create a file (has to be
binary for python3) to write to, then <tt class="docutils literal"><span class="pre">pickle.dump(mymodel,</span> <span class="pre">f)</span></tt></p>
<p>subsequently open the file to read from and <tt class="docutils literal"><span class="pre">mymodel</span> <span class="pre">=</span> <span class="pre">pickle.read(f)</span></tt>
the loaded file will have any required Textures included automatically
including bump and reflection maps. However the shader will still
need to be set with <tt class="docutils literal"><span class="pre">set_shader()</span></tt></p>
</div></blockquote>
<p>Loading from a pickle file is significantly faster than parsing a
wavefront obj file but (because of the less efficient image compression)
the disk space used will be much higher.</p>
</div></blockquote>
</li>
<li><p class="first">How to have lots of rapidly changing text on the screen (such as location
game-status readouts etc) whithout having to create new String objects
all the time (with associated processor load)</p>
<blockquote>
<div><p>This can be done using the String.quick_change() method. NB at the
moment only in the develop branch.</p>
<p>When you first create the string you need to make it big enough to
fit in any additional characters you may send to quick_change()
subsequently. At the moment it doesn&#8217;t cope with multi-line Strings.</p>
<p>There is an example in pi3d_demos/ForestQuickNumbers.py (at the moment
only in develop branch)</p>
</div></blockquote>
</li>
<li><p class="first">How to have a large amount of text without creating hundreds of extra
polygons for the gpu to render?</p>
<blockquote>
<div><p>The String object has a little rectangle for each letter, each of
which needs four vertices and two triangles. If the text does not
need to be changed then it is better to use the FixedString class.
The object inherits from Texture with the provided text drawn onto it.
It also creates a simple sprite with four vertices and two triangles
that can be used to draw the texture. There are filters that can
produce effects such as blurring, outlining and normal map generation.</p>
</div></blockquote>
</li>
<li><p class="first">How to profile code to find where the bottlenecks are? For example
to find if it&#8217;s worth doing something complicated with numpy or &#8216;blitting&#8217;
small areas of the screen as in the NumpyBalls demo?</p>
<blockquote>
<div><p>The python profiler cProfile is very easy to use but I have found
it struggles to find directories from the code and gives quirky
information unless I do something like:</p>
<div class="highlight-python"><div class="highlight"><pre>$ cd ~/pi3d_demos
$ python -m cProfile ~/pi3d_demos/NumpyBalls.py &gt; result.txt
</pre></div>
</div>
</div></blockquote>
</li>
<li><p class="first">Is it possible to use pi3d on my laptop or desktop computer
ideally running windows?</p>
<blockquote>
<div><p>If your computer has a suitable graphics card then it is possible
to set up pi3d in a linux environment see <a class="reference external" href="http://pi3d.github.com/html/index.html">ReadMe</a> . It ought to be
pssible to set it up with a very similar procedure on mac but I havn&#8217;t
tried (let me know if you do!) On windows the only route at the
moment is using something like VMWare:</p>
<div class="highlight-python"><div class="highlight"><pre>Setup:

VMWare Client
3d Accel.. activated!
LinuxMint Installation (Ubundu-based and Debian base version works)

very important
    mesa-utils-extra
    python-numpy
and the rest as described in the Pi3D documentation

Important: pi3d scripts must be started with sudo

e.g. sudo python ./Pi3D2.py

In the VM it does not run very smooth, but it works without errors.

After testing this setup  I&#39;ve installed the setup to a partition... runs like a charm :-)
</pre></div>
</div>
<p>comments by &#64;hesspet in groups.google.com</p>
</div></blockquote>
</li>
</ol>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="ReadMe.html"
                        title="previous chapter">Introduction to Pi3D</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="GPUexplain.html"
                        title="next chapter">3D Graphics Explanation</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/FAQ.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="GPUexplain.html" title="3D Graphics Explanation"
             >next</a> |</li>
        <li class="right" >
          <a href="ReadMe.html" title="Introduction to Pi3D"
             >previous</a> |</li>
        <li><a href="index.html">pi3d 1.10 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, The pi3d team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>